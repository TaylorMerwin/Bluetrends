# docker-compose.yml
services:
  broker:
    image: apache/kafka:latest
    container_name: broker
    hostname: broker
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: EXTERNAL://0.0.0.0:29092,INTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: EXTERNAL://localhost:29092,INTERNAL://broker:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:9093"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - kafka-data:/var/lib/kafka/data

  python:
    build:
      context: .
      dockerfile: python/Dockerfile
    container_name: python
    hostname: python
    volumes:
      - ./src/ingestion:/home/app
    working_dir: /home/app
    command: sleep infinity
    depends_on:
      - broker

  airflow:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    image: custom-airflow:2.10.5
    container_name: airflow
    volumes:
      - ./src/airflow:/opt/airflow/dags
      - ./data/airflow:/usr/local/airflow
      - /var/run/docker.sock:/var/run/docker.sock
      - ./:/opt/project
    working_dir: /opt/project
    ports:
      - "8080:8080"
    command: webserver
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=mysql+mysqlconnector://${MYSQL_USERNAME}:${MYSQL_PASSWORD}@db:3306/${MYSQL_DATABASE}
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - broker
      - python
      - db

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    build:
      context: .
      dockerfile: spark/Dockerfile
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master

      # The correct environment var name:
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/tmp/spark-events

    ports:
      - "8081:8080"
    volumes:
      - ./src/processing:/opt/spark-apps
      - spark-events:/tmp/spark-events
      - ./models:/models
    depends_on:
      - broker
    env_file:
      - ./.env

  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    build:
      context: .
      dockerfile: spark/Dockerfile
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./models:/models
    depends_on:
      - spark-master
    env_file:
      - ./.env

  spark-worker-2:
    image: bitnami/spark:3.5
    container_name: spark-worker-2
    build:
      context: .
      dockerfile: spark/Dockerfile
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./models:/models
    depends_on:
      - spark-master
    env_file:
      - ./.env

  db:
    image: mysql:9.2.0
    container_name: db
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USERNAME}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
      - ./mysql/initdb:/docker-entrypoint-initdb.d
    restart: always

  dash:
    container_name: dash
    build:
      context: ./src/dashboard
      dockerfile: Dockerfile
    ports:
      - "8051:8051"
    depends_on:
      - db
    volumes:
      - ./src/dashboard:/app
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_ENGINE_URL}
      MYSQL_USER: ${MYSQL_USERNAME}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    env_file:
      - ./.env

volumes:
  kafka-data:
  mysql-data:
  spark-events:
